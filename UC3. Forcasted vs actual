from pyspark.sql import SparkSession
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Initialize SparkSession
spark = SparkSession.builder \
    .appName("EmployeeLeavingForecasting") \
    .getOrCreate()

# Aggregate data by OrganizationType and quarters of 2023
aggregated_df = merged_df_spark.groupBy('OrganizationType', 'Quarterly_Trend_Num').count()

# Create an empty DataFrame to hold forecast results
forecast_df = spark.createDataFrame([], schema="OrganizationType STRING, Q1_2024 INT, Q2_2024 INT, Q3_2024 INT, Q4_2024 INT")

# Train SARIMA model for each OrganizationType and forecast for 2024 quarters
for org_type in aggregated_df.select('OrganizationType').distinct().rdd.flatMap(lambda x: x).collect():
    org_type_df = aggregated_df.filter(col('OrganizationType') == org_type)
    org_type_df = org_type_df.orderBy('Quarterly_Trend_Num')

    # Convert DataFrame to Pandas for SARIMA model
    pandas_df = org_type_df.toPandas()
    pandas_df.set_index('Quarterly_Trend_Num', inplace=True)

    # Train SARIMA model
    model = SARIMAX(pandas_df['count'], order=(1, 0, 0), seasonal_order=(1, 0, 0, 4))
    fitted_model = model.fit()

    # Forecast for 2024 quarters and round the values to integers
    forecast = fitted_model.forecast(steps=4).round().astype(int)

    # Create DataFrame for the forecast results
    forecast_values = [(org_type,) + tuple(forecast)]
    forecast_org_type_df = spark.createDataFrame(forecast_values, schema="OrganizationType STRING, Q1_2024 INT, Q2_2024 INT, Q3_2024 INT, Q4_2024 INT")

    # Union the forecast DataFrame with the overall forecast DataFrame
    forecast_df = forecast_df.union(forecast_org_type_df)

# Display forecast DataFrame
forecast_df.show()

# Stop SparkSession
spark.stop()
